version: "3.3"

    # beta 6 exposes just a flask route
    # beta 8 correctly exposes json routes - logs undefined
    # beta 13.2 streams out logs - but stuck endpoint
    # beta 16 return jsonified list (compact view)
    # beta 16.1 returns json {name:, linenr:}
    # beta 16.2 strict slashes=False
    # beta 16.3 keep both behaviours in diff urls
    # beta 16.6 tasks with desired: running
    # beta 17.2 decorate client as resource, client info
    # 0.2 as 17.2
    # 0.2.1 include new setup.py version
    # 0.2.1.1 test other log than self - occasional timeout still exists on all urls as well (not only logs),
    # solution: may need to remove ::1     localhost ip6-localhost ip6-loopback from /etc/hosts
    # 0.2.3 include node labels, availability
    # 0.2.4 Add tasks by service name
    # 0.2.4.1 Add service route
    # 0.2.5 Add get tasks by service name route, 0.2.5.1 fix
    # 0.2.5.2 Return empty task list
    # 0.2.6 Refine search services by name, tasks
    # 0.2.6.1 Fix list routes
    # 0.2.6.2 Add active node by getting environ['DOCKER_NODE']
    # 0.2.7 Fix route to current nodename
    # 0.2.7.1 Add Requests module, 0.2.7.2 fix port
    # 0.2.7.3 Add tasks json route and middleware
    # 0.2.7.4 Fix empty list bug in tasks
    # 0.2.8 Add fields to task, get node by id, 0.2.8.1 fix decorator
    # 0.2.8.2 Add Slot check for global services

    # 0.3 Split into data-provider and manager services
    # 0.3.0 test data-providers from manager, 0.3.1 fix ips
    # 0.3.2 Provide extensive node test from manager
    # 0.3.3 Add container/id/logs routes on data-provider
    # 0.3.4 Add stream log route to data-provider, 0.3.4.1, 0.3.4.2, 0.3.4.3, 0.3.4.4
    # 0.3.5 Add mimetype=text/event-stream
    # 0.3.6 Add tail/lines route to data-provider
    # 0.3.6.1 Use json.dumps() on streams, 0.3.6.2 fix formatting
    # 0.3.7 introduce timeouts, 0.3.7.1
    # 0.3.7.2 threaded=True for data-provider
    # 0.3.7.5 test stream request from manager
    # 0.3.7.6 Add reentrant iter_lines hack
    # 0.3.7.7 Test manager with iter_content()
    # 0.3.7.8 iter content with decoding and chunk size = None, 0.3.7.9
    # 0.3.8 format chars in iter content, 0.3.8.1
    #   Both iter_lines and iter_content lose data

    # 0.4 Setup.py install eventlet, flask-socketio, 0.4.1 fix app.run()
    # 0.4.2 Add threaded server
    # 0.4.3 Add async mode on SocketIO init
    # 0.5 Include socketIO_client

    # 0.5.1 Streaming requests succeeded without sockets, using chunk size=1024
    # 0.5.2 Test again using iter_lines -> Success
    # 0.5.2.1, 0.5.3 Test with text/plain instead of text/event-stream -> Success with Firefox, Edge
    # 0.5.4 Add teststream route for manager
    # 0.5.5 Add route tasks_by_id for manager
    # 0.5.6 Test node_ip, 0.5.6.2 Fix Leader key not exists => Fixed
    # 0.5.7 Implement return container id from task id & service name, 0.5.7.1 Return not found
    # 0.5.8 Add routes for logs, /compact, /stream, /tail/:lines, 0.5.8.1 Resize chunk size to 256 for tail
    # 0.5.9 Clean up docker_provider get container by task function, provider_port as constant
    # 0.5.9.1 Data provider port as env variable
    # 0.5.9.2 Chunk size of stream readers to 64 (smaller logs), 0.5.9.3 size=1 test
    # 0.5.9.4 Install curl on manager
    # 0.5.10 Add version=auto on docker client
    # 0.5.11 Add container.logs logs=True parameter, 0.5.12, 0.5.13
    # 0.5.14 Docker client not closed
    # 0.5.15 Set debug=True on server, 0.5.16 change logs/stream to text/event-stream, 0.5.17 route streamout
    # 0.5.18 Docker api 1.30 fixed
    # 0.5.19 Test logs/stream without reload
    # 0.5.20 Use flask instead of eventlet-socketio as server
    # 0.6.0 Remove socketio wrappers from manager, data provider (Keep in Dockerfile)
    # 0.6.1 Fix manager threaded=True
    # 0.6.2 Set mimetype plain, content type event-stream, debug False
    # 0.6.3 Attempt stream json from compact route
    # 0.6.4 Use socketio eventlet server
    # 0.6.5 Flexible chunk size for tail, handle ApiError
    # 0.6.6 Resize chunk size to 2048 for tail < 20, use resource context on requests.get(stream)
    # 0.6.7 Reset to no resource context
    # 0.7.0 Docker Py version to 3.3.0
    # 0.7.1 Removed container.reload() on streaming logs:
      # Bug:  stream=True from container.logs() does not instantly include the last few lines, that is why /tail hangs
    # 0.7.2 Attempt fix without encoding
    # 0.7.3 Encode on manager only
    # 0.7.4 Use sleep(1) between reading lines
    # 0.7.5 Use next() in generator instead of for
    # 0.7.6 Use yield from instead of iterating logs. 0.7.6.1, 0.7.6.2, 0.7.6.3, 0.7.6.4
    # 0.7.7 Return generator with direct_passthrough
    # 0.7.8 Lazy load logs from provider
    # 0.7.9 Add prints for each line yielded on provider
    # 0.7.10 Print each yield
    # 0.7.11 Use low-level API Client in provider
    # 0.7.12 Revert back to flask wsgi server, bug almost fixed: eventlet missed response chunks, flask also misses chunks
    # 0.7.13 Add service logs route, 0.7.13.1
    # 0.7.14 Return direct generators on streaming Responses -> Success
    # 0.7.14.1 Include route tail on service logs, 0.7.14.2 chunk_size=1 on manager routes
    # 0.7.15 Clean up working version 0.7.14.2

    # 0.8 install flask_hal
    # 0.8.0 test HAL on / and /service, 0.8.0.1, 0.8.0.3, 0.8.0.4
    # 0.8.1 Update with Self and URL_PREFIX
    # 0.8.2 Attempt export Document from docker_provider, 0.8.2.2

    # 0.9 Remove flask_hal, provide links for most routes
    # 0.9.0 Cleanup manager, provider
    # 0.9.1 Add timestamp on json logs

    # Reminder to change data-provider port on each environment

services:

  whalefisher-manager:
    image: registry.dream:5001/whalefisher-manager:0.9.1
    deploy:
      replicas: 1
    environment:
      - DOCKER_NODE: "{{.Node.Hostname}}"
      - DATA_PROVIDER_PORT: 8080
      - PUBLISH_PORT: 80
      - EXT_DOMAIN_NAME: "http://35.189.200.49"
      # Above only works for gcloud compute instances, use own ip or domain name to generate uris
    ports:
      - "80:5000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

  whalefisher-data_provider:
    image: registry.dream:5001/whalefisher-data_provider:0.9.1
    deploy:
      mode: global
      endpoint_mode: dnsrr
    environment:
      - DOCKER_NODE={{.Node.Hostname}}
    ports:
      - target: 5000
        published: 8080
        protocol: tcp
        mode: host
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock